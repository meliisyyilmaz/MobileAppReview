# -*- coding: utf-8 -*-
"""appReviews.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D706GyecqHL0u_aTHrBblAluRHJ_nuPl
"""

!pip install google-play-scraper

!pip install vaderSentiment

!pip install transformers torch

"""###Libraries"""

from google_play_scraper import Sort, reviews
import pandas as pd
import os
import re
import seaborn as sns
import matplotlib.pyplot as plt

from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from scipy.special import softmax
import torch
from tqdm import tqdm
import openai
import time

"""###Data Processing"""

def get_reviews(app_package, n_reviews=20000):
    all_reviews = []
    count = 0

    while count < n_reviews:
        result, _ = reviews(
            app_package,
            lang='en',
            country='us',
            sort=Sort.NEWEST,
            count=200,
            filter_score_with=None
        )
        all_reviews.extend(result)
        count = len(all_reviews)

    df = pd.DataFrame(all_reviews)
    return df.head(n_reviews)

os.makedirs("data/raw", exist_ok=True)

duolingo_reviews = get_reviews("com.duolingo", n_reviews=20000)
duolingo_reviews.to_csv("data/raw/duolingo_reviews.csv", index=False)

duolingo_reviews.to_csv("data/raw/duolingo_reviews.csv", index=False)

df = pd.read_csv("data/raw/duolingo_reviews.csv")
df = df[["score", "content", "at"]].dropna()
df.info()

df["at"] = pd.to_datetime(df["at"])

df

df["at"].dtypes

def clean_text(text):
    text = str(text).lower()
    text = re.sub(r"http\S+", "", text)
    text = re.sub(r"[^a-zA-Z\s]", "", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

df["cleaned"] = df["content"].apply(clean_text)

df[["content", "cleaned"]]

"""#### Adding Sentiment score based and text based"""

def label_sentiment(score):
    if score >= 4:
        return "positive"
    elif score == 3:
        return "neutral"
    else:
        return "negative"

df["sentiment_score_based"] = df["score"].apply(label_sentiment)

analyzer = SentimentIntensityAnalyzer()

def vader_sentiment(text):
    score = analyzer.polarity_scores(text)["compound"]
    if score >= 0.05:
        return "positive"
    elif score <= -0.05:
        return "negative"
    else:
        return "neutral"

df["sentiment_text_based"] = df["cleaned"].apply(vader_sentiment)

df

df["sentiment_score_based"].value_counts(normalize=True)

model_name = "cardiffnlp/twitter-roberta-base-sentiment-latest"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

def transformer_sentiment(text):
    encoded_input = tokenizer(text, return_tensors="pt", truncation=True)
    with torch.no_grad():
        output = model(**encoded_input)
    scores = softmax(output.logits.numpy()[0])
    labels = ["negative", "neutral", "positive"]
    return labels[scores.argmax()]

"""trying with sample first"""

df_sample = df.sample(1000, random_state=42).copy()  # for testing speed
df_sample["sentiment_cardiff"] = df_sample["cleaned"].apply(transformer_sentiment)

df_sample[["score", "cleaned", "sentiment_score_based", "sentiment_text_based", "sentiment_cardiff"]].sample(5)

(df_sample["sentiment_text_based"] == df_sample["sentiment_cardiff"]).mean()

"""Now let's do that on whole data, and keep analyzing!"""

tqdm.pandas()

df["sentiment_cardiff"] = df["cleaned"].progress_apply(transformer_sentiment)

agreement = (df["sentiment_text_based"] == df["sentiment_cardiff"]).mean()
print(f"Agreement rate: {agreement:.2%}")

mismatches = df[df["sentiment_text_based"] != df["sentiment_cardiff"]]
mismatches[["score", "cleaned", "sentiment_text_based", "sentiment_cardiff"]].sample(5)

interesting = mismatches.sample(10)
for _, row in interesting.iterrows():
    print(f"⭐️ {row['score']} | Text: {row['cleaned']}\n→ Score-based: {row['sentiment_text_based']} | AI-based: {row['sentiment_cardiff']}\n")

"""Let's explore the mismatch ones"""

conf_mat = pd.crosstab(df["sentiment_text_based"], df["sentiment_cardiff"])
sns.heatmap(conf_mat, annot=True, fmt="d", cmap="YlGnBu")
plt.title("Score-Based vs AI Sentiment (CardiffNLP)")
plt.ylabel("Score-Based")
plt.xlabel("AI-Based")
plt.show()

conf_mat = pd.crosstab(df["sentiment_score_based"], df["sentiment_cardiff"])
sns.heatmap(conf_mat, annot=True, fmt="d", cmap="YlGnBu")
plt.title("Score-Based vs AI Sentiment (CardiffNLP)")
plt.ylabel("Score-Based")
plt.xlabel("AI-Based")
plt.show()

pd.crosstab(df["sentiment_text_based"], df["sentiment_cardiff"], normalize='index')

"""High aggrement on positive class, makes sense.
However, on neutral class they did not get along very well.
"""

pd.crosstab(df["sentiment_score_based"], df["sentiment_cardiff"], normalize='index')

pd.crosstab(df["sentiment_text_based"], df["sentiment_score_based"], normalize='index')

"""So far, the results actually make a lot of sense.

Both positive and negative reviews are understood pretty well, no matter whether you're using star ratings or AI models. But when it comes to the neutral reviews things are different.
That is expected.

Most people don’t leave a 3-star review and say, "it is average". That’s why score-based sentiment struggles with neutrality — it’s not always clear what a 3-star rating really means.

What I’m actually curious about now is how CardiffNLP compares to VADER in these tricky situations. Can a transformer model actually spot subtle frustration or passive-aggressive tone — the kind that a rule-based system might miss?

That’s what exploring next?

My hypothesis is:
**CardiffNLP should be better at detecting passive-aggressive or subtly negative reviews — especially when VADER misses them.**

Let's see
"""

vader_vs_cardiff = df[df["sentiment_text_based"] != df["sentiment_cardiff"]]
print(f"Total mismatches: {len(vader_vs_cardiff)}")

#Random samples from the disagreements
for _, row in vader_vs_cardiff.sample(25, random_state=42).iterrows():
    print(f"⭐️ {row['score']} | Text: {row['cleaned']}\n→ VADER: {row['sentiment_text_based']} | Cardiff: {row['sentiment_cardiff']}\n")

"""### Let's see the label reasoning"""

!pip install openai

# Your OpenAI API key
openai.api_key = ""

# Lists to collect results
gpt_sentiments = []
gpt_reasons = []

def ask_gpt_sentiment(review_text, star_score):
    prompt = f"""
You're analyzing app reviews. Each review includes a user-written comment and a star score (1 to 5).

Your task is to:
1. Determine the overall sentiment of the review text: positive, neutral, or negative.
2. Explain your reasoning in 1-2 sentences.

Review Text: "{review_text}"
Star Score: {star_score}

Sentiment:
"""

    try:
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
            max_tokens=200
        )
        reply = response["choices"][0]["message"]["content"]
        return reply
    except Exception as e:
        return f"error\n{str(e)}"

# Run over all mismatches (or sample)
for _, row in vader_vs_cardiff.iterrows():
    reply = ask_gpt_sentiment(row["cleaned"], row["score"])
    lines = reply.strip().split("\n")
    sentiment = lines[0].strip().lower()
    reason = " ".join(lines[1:]).strip()
    gpt_sentiments.append(sentiment)
    gpt_reasons.append(reason)
    time.sleep(1.2)  # avoid rate limit

# Add results to DataFrame
vader_vs_cardiff["sentiment_gpt"] = gpt_sentiments
vader_vs_cardiff["reason_gpt"] = gpt_reasons

vader_vs_cardiff = vader_vs_cardiff.iloc[:len(gpt_sentiments)].copy()
vader_vs_cardiff["sentiment_gpt"] = gpt_sentiments
vader_vs_cardiff["reason_gpt"] = gpt_reasons

vader_vs_cardiff

"""In this case, GPT 4.0 is requiring full access API, for future it can be considered."""

